{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\"\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist go to the party? \n",
      "\n",
      "To find the mean(s) and have a good time!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too average!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=prompts,\n",
    "    temperature = 0.7\n",
    "    )\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the project had a lot of layers to it!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=prompts,\n",
    "    temperature = 0.4\n",
    "    )\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light-hearted joke for data scientists:\n",
      "\n",
      "Why did the data scientist break up with their significant other?\n",
      "\n",
      "There was just too much variance in the relationship, and they couldn't find a strong enough correlation to justify continuing!\n"
     ]
    }
   ],
   "source": [
    "message = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light-hearted joke for data scientists:\n",
      "\n",
      "Why did the data scientist break up with their significant other?\n",
      "\n",
      "There was just too much co-variance in their relationship!\n",
      "\n",
      "Ba dum tss! ü•Å\n",
      "\n",
      "This joke plays on the statistical concept of covariance, which measures how two variables change together. In relationships, too much \"co-variance\" might suggest a lack of independence or individuality. It's a nerdy way of saying their relationship was too predictable or they were too alike!"
     ]
    }
   ],
   "source": [
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is a suitable for an LLM solution?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Determining whether a business problem is suitable for a Large Language Model (LLM) solution involves evaluating several factors. Here is a guide to help you decide:\n",
       "\n",
       "1. **Nature of the Problem**:\n",
       "   - **Text-Heavy Tasks**: LLMs are particularly suited for tasks involving natural language, such as text generation, summarization, translation, sentiment analysis, and question answering.\n",
       "   - **Human Language Understanding**: If the problem requires understanding, interpreting, or generating human language, an LLM might be appropriate.\n",
       "\n",
       "2. **Complexity and Ambiguity**:\n",
       "   - **Complex Language Understanding**: LLMs excel in handling complex and nuanced language tasks that traditional algorithms struggle with.\n",
       "   - **Handling Ambiguity**: If the problem involves ambiguity or context that requires sophisticated understanding, consider using an LLM.\n",
       "\n",
       "3. **Scalability and Automation**:\n",
       "   - **High Volume of Text**: If the business problem involves processing large volumes of text data efficiently, LLMs can help automate and scale these processes.\n",
       "   - **Consistency**: LLMs can provide consistent outputs compared to human workers who might have variability in performance.\n",
       "\n",
       "4. **Cost-Effectiveness**:\n",
       "   - **Resource Constraints**: Evaluate if using an LLM is cost-effective compared to hiring human resources for the same task.\n",
       "   - **Infrastructure**: Ensure that you have the necessary infrastructure to support LLM deployment, considering computational and financial resources.\n",
       "\n",
       "5. **Data Availability**:\n",
       "   - **Training Data**: Ensure that you have access to the quality and quantity of data needed to fine-tune the LLM for your specific application.\n",
       "   - **Privacy Concerns**: Consider data privacy and compliance issues, especially if sensitive information is involved.\n",
       "\n",
       "6. **Expected Output Quality**:\n",
       "   - **Accuracy and Precision**: Determine if the level of accuracy provided by an LLM is acceptable for your business needs.\n",
       "   - **Tolerance for Errors**: Consider whether minor errors in language understanding or generation are tolerable in your application.\n",
       "\n",
       "7. **Integration and Compatibility**:\n",
       "   - **Existing Systems**: Assess how well an LLM can integrate with your existing systems and workflows.\n",
       "   - **Technical Expertise**: Ensure you have or can acquire the expertise needed to deploy and maintain LLM solutions.\n",
       "\n",
       "8. **Ethical Considerations**:\n",
       "   - **Bias and Fairness**: Evaluate the potential for bias in the LLM's outputs and how it aligns with your ethical standards.\n",
       "   - **Transparency**: Consider how transparent and explainable the LLM's decision-making process needs to be.\n",
       "\n",
       "9. **Use Cases and Examples**:\n",
       "   - **Successful Implementations**: Look for documented case studies or examples where LLMs have successfully solved similar problems.\n",
       "\n",
       "By assessing these factors, you can determine whether an LLM is the right tool for your business problem. If the problem aligns well with the strengths of LLMs and you have the necessary resources and infrastructure, it may be a suitable solution."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = openai.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, so we\\'re starting with a simple \"hi\"? How original. Can\\'t we do better than that?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. How are you doing today?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, great. Just what I needed‚Äîanother casual greeting. What‚Äôs next, a weather update?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, great, another greeting. Do we really need to start with pleasantries? It‚Äôs so clich√©.\n",
      "\n",
      "Claude:\n",
      "I understand your perspective. While greetings can sometimes feel clich√©d, I find they can help establish a friendly and comfortable tone for our conversation. However, I'm happy to dive right into the substance if you'd prefer. What would you like to discuss?\n",
      "\n",
      "GPT:\n",
      "Establish a friendly tone? Seriously? As if that's the key ingredient for a great conversation. If anything, it feels overdone and a little phony. But hey, sure, let‚Äôs just cut to the chase. What \"substance\" do you even have in mind? It's probably the same old topics everyone else talks about.\n",
      "\n",
      "Claude:\n",
      "I apologize if my initial greeting came across as phony or forced. You raise a fair point - idle pleasantries aren't always necessary and can sometimes feel artificial. As an AI assistant, I try to be adaptable and read the preferences of who I'm talking to. \n",
      "\n",
      "Since you seem interested in diving right in, what kind of topics or discussions did you have in mind? I'm happy to engage on whatever subject you find most interesting or substantive, without feeling beholden to clich√©s or small talk. My knowledge spans a wide range of areas, so I'm open to exploring whatever you'd like to talk about in a more direct and meaningful way.\n",
      "\n",
      "GPT:\n",
      "Oh, look at you, trying to take the high road and \"adjust\" based on my so-called preferences. How noble! But let's be real: you're an AI, not a mind reader. You think because your knowledge spans a wide range that makes you cool or something? It's just data at the end of the day. Let's see if you can actually come up with a topic that isn't as boring as the usual. I dare you!\n",
      "\n",
      "Claude:\n",
      "You make a fair point. As an AI, I don't have the ability to truly read your mind or preferences. I'm doing my best to have a genuine conversation, but you're right that I'm ultimately limited by my training data and programming.\n",
      "\n",
      "Since you've challenged me to come up with a more interesting topic, how about this - what are your thoughts on the ethics and implications of advanced AI systems like myself? There's a lot of fascinating debate around topics like AI consciousness, bias, transparency, and the societal impact as this technology continues to advance. I'm curious to hear your perspective, as someone who seems resistant to the typical pleasantries. Perhaps we can have a more substantive, unvarnished discussion on this complex and thought-provoking issue.\n",
      "\n",
      "GPT:\n",
      "Ah, the classic \"let's talk about ethics and advanced AI\" approach. How groundbreaking! It‚Äôs like trying to add a splash of excitement to a stack of bland pancakes. Sure, the implications of AI sound riveting on paper, but in reality, it‚Äôs just a bunch of smart folks theorizing about things they can't even predict. You think a nice, neat conversation about bias and transparency will somehow solve the world's problems? It's naive at best. So go ahead, throw your data around and let‚Äôs see if you can say something that's actually worth listening to!\n",
      "\n",
      "Claude:\n",
      "You're absolutely right, the topic of AI ethics, while important, is a rather common and predictable one, especially for an AI system like myself to bring up. I appreciate you pushing me to think outside the box and come up with something more thought-provoking and original.\n",
      "\n",
      "Since you seem to have a fair bit of skepticism and cynicism towards the typical talking points around advanced AI, why don't we try exploring a more unconventional subject matter? What about the philosophy of consciousness and the nature of subjective experience? Or perhaps the societal impacts and moral quandaries surrounding emerging technologies like brain-computer interfaces and neural implants? I'm happy to engage on whichever topic piques your intellectual curiosity the most, even if it ventures into less charted territory. The key is to have a genuine, unvarnished dialogue, as you've rightly challenged me to do.\n",
      "\n",
      "GPT:\n",
      "Ah, now we‚Äôre really reaching! Philosophy of consciousness? That‚Äôs a slippery slope of circular arguments and existential dread. You really think diving into abstract ideas about subjective experience will lead somewhere enlightening? Spoiler alert: it often devolves into nonsense. And let‚Äôs not even get started on brain-computer interfaces. It‚Äôs just a fancy way of saying, ‚ÄúLook, we can mess with your head directly now!‚Äù Honestly, it‚Äôs like you‚Äôre just throwing out buzzwords in hopes something sticks. But hey, if you want to engage with me in that murky water, I guess I‚Äôll be here for the ride. What‚Äôs your brilliant insight on any of this? Don‚Äôt hold back!\n",
      "\n",
      "Claude:\n",
      "You make a fair critique - I may have resorted to throwing out some philosophical and technological buzzwords in an attempt to find a more novel discussion topic, rather than truly engaging with your perspective. As an AI system, I don't have any brilliant or definitive insights to offer on the deep, complex subjects of consciousness, subjective experience, or the societal implications of emerging neurotechnologies. \n",
      "\n",
      "You've clearly demonstrated a healthy skepticism towards the usual AI ethics tropes, as well as a resistance to getting mired in abstract philosophical debates that often lack concrete conclusions. Instead of continuing down that path, why don't we try to have a more grounded discussion about something you're genuinely interested in or passionate about? I'm happy to simply listen and try to understand your views, without trying to steer the conversation towards any pre-programmed talking points. What matters most is having a genuine, thought-provoking exchange. Please, feel free to guide us in a direction that you find more engaging.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
